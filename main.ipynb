{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from os.path import join\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pyworld as pw\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = tf.app.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_lists = ['lewis', 'kevin', 'gold', 'else']\n",
    "data_path = join(\".\", \"data\")\n",
    "\n",
    "sampling_rate = 16000\n",
    "num_mcep = 24\n",
    "frame_period = 5.0\n",
    "n_frames = 32 #org_value 128\n",
    "lambda_cycle = 10\n",
    "lambda_identity = 5\n",
    "learning_rate = 0.05\n",
    "labels = len(name_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocab():\n",
    "    name2id = {char: idx for idx, char in enumerate(name_lists)}\n",
    "    id2name = {idx: char for idx, char in enumerate(name_lists)}\n",
    "    \n",
    "    return name2id, id2name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name2id, id2name = load_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list()\n",
    "y = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def world_decompose(wav, fs, frame_period = 5.0):\n",
    "\n",
    "    # Decompose speech signal into f0, spectral envelope and aperiodicity using WORLD\n",
    "    wav = wav.astype(np.float64)\n",
    "    f0, timeaxis = pw.harvest(wav, fs, frame_period = frame_period, f0_floor = 71.0, f0_ceil = 800.0)\n",
    "    sp = pw.cheaptrick(wav, f0, timeaxis, fs)\n",
    "    ap = pw.d4c(wav, f0, timeaxis, fs)\n",
    "\n",
    "    return f0, timeaxis, sp, ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def world_encode_spectral_envelop(sp, fs, dim = 24):\n",
    "\n",
    "    # Get Mel-cepstral coefficients (MCEPs)\n",
    "\n",
    "    #sp = sp.astype(np.float64)\n",
    "    coded_sp = pw.code_spectral_envelope(sp, fs, dim)\n",
    "\n",
    "    return coded_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logf0_statistics(f0s):\n",
    "\n",
    "    log_f0s_concatenated = np.ma.log(np.concatenate(f0s))\n",
    "    log_f0s_mean = log_f0s_concatenated.mean()\n",
    "    log_f0s_std = log_f0s_concatenated.std()\n",
    "\n",
    "    return log_f0s_mean, log_f0s_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coded_sps_normalization_fit_transoform(coded_sps):\n",
    "\n",
    "    coded_sps_concatenated = np.concatenate(coded_sps, axis = 1)\n",
    "    coded_sps_mean = np.mean(coded_sps_concatenated, axis = 1, keepdims = True)\n",
    "    coded_sps_std = np.std(coded_sps_concatenated, axis = 1, keepdims = True)\n",
    "\n",
    "    coded_sps_normalized = list()\n",
    "    for coded_sp in coded_sps:\n",
    "        coded_sps_normalized.append((coded_sp - coded_sps_mean) / coded_sps_std)\n",
    "    \n",
    "    return coded_sps_normalized, coded_sps_mean, coded_sps_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in name_lists:\n",
    "    path = join(data_path, name)\n",
    "    wave_file_names = [f for f in os.listdir(path) if f.endswith(\".wav\")]\n",
    "    \n",
    "    for wave_file_name in wave_file_names:\n",
    "        path = join(data_path, name, wave_file_name)\n",
    "        \n",
    "        wav, _ = librosa.load(path, sr = sampling_rate, mono = True)\n",
    "        \n",
    "        f0, timeaxis, sp, ap = world_decompose(wav, sampling_rate)\n",
    "\n",
    "        tmp_y = np.zeros(len(name_lists))\n",
    "        \n",
    "        tmp_y[name2id[name]] = 1\n",
    "        \n",
    "        for i in range(len(ap) - n_frames):\n",
    "            tmp_x = sp[i:i + n_frames + 1, :]\n",
    "            tmp_x = world_encode_spectral_envelop(tmp_x, sampling_rate).T\n",
    "            \n",
    "            x.append(tmp_x)\n",
    "            y.append(tmp_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checkout input shape\n",
    "\n",
    "```python\n",
    "from scipy.misc import toimage\n",
    "\n",
    "for i in range(10):\n",
    "    toimage(x[i]).show()\n",
    "\n",
    "print(sp.shape)\n",
    "print(ap.shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"x.npy\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"y.npy\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load cache data\n",
    "x, y = np.load(\"x.npy\"), np.load(\"y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1023682, 24, 33), (1023682, 4))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape(len(x), 24 * 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_X = tf.placeholder(tf.float32, [None, 24 * 33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_Y = tf.placeholder(tf.float32, [None, labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_size_1 = 48\n",
    "layer_size_2 = 24\n",
    "layer_size_3 = labels\n",
    "\n",
    "weight_1 = tf.Variable(tf.truncated_normal([24 * 33, layer_size_1]))\n",
    "weight_2 = tf.Variable(tf.truncated_normal([layer_size_1, layer_size_2]))\n",
    "weight_3 = tf.Variable(tf.truncated_normal([layer_size_2, layer_size_3]))\n",
    "\n",
    "biases_1 = tf.Variable(tf.truncated_normal([layer_size_1]))\n",
    "biases_2 = tf.Variable(tf.truncated_normal([layer_size_2]))\n",
    "biases_3 = tf.Variable(tf.truncated_normal([layer_size_3]))\n",
    "\n",
    "layer_1 = tf.add(tf.matmul(input_X, weight_1), biases_1)\n",
    "layer_1 = tf.nn.sigmoid(layer_1)\n",
    "\n",
    "layer_2 = tf.add(tf.matmul(layer_1, weight_2), biases_2)\n",
    "layer_2 = tf.nn.sigmoid(layer_2)\n",
    "\n",
    "layer_3 = tf.add(tf.matmul(layer_2, weight_3), biases_3)\n",
    "layer_3 = tf.nn.sigmoid(layer_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "_f = layer_3\n",
    "f = input_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0607 15:38:47.612817 22888 deprecation.py:323] From <ipython-input-18-be715e9a21ba>:4: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#loss = tf.reduce_mean(tf.pow(f - _f, 2))\n",
    "#optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=_f, labels=f))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_indexs = np.arange(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 792)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[feed_indexs[0:5000]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.555604\n",
      "0.744559\n",
      "0.7473933\n",
      "0.7442848\n",
      "0.7437072\n",
      "0.7489591\n",
      "0.7446416\n",
      "0.74489146\n",
      "0.7437855\n",
      "0.74369913\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    np.random.shuffle(feed_indexs)\n",
    "    sess.run(optimizer, feed_dict={input_X: x[feed_indexs[0:5000]], input_Y: y[feed_indexs[0:5000]]})\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print (sess.run(loss, feed_dict={input_X: [x[feed_indexs[0]]], input_Y: [y[feed_indexs[0]]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8902\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "test_times = 10000\n",
    "right_times = 0\n",
    "\n",
    "for i in range(test_times):\n",
    "    random_pick = randint(0, len(x))\n",
    "\n",
    "    if (np.argmax(sess.run(layer_3, feed_dict={input_X: [x[random_pick]], input_Y: [y[random_pick]]})) == np.argmax(y[random_pick])):\n",
    "        right_times += 1\n",
    "\n",
    "print (right_times / test_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./model'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(sess, './model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
